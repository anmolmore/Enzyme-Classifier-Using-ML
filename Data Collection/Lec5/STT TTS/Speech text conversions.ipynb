{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Speech to text conversions using different API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# obtain path to \"english.wav\" in the same folder as this script\n",
    "from os import path\n",
    "AUDIO_FILE = \"C:/Users/31072/Desktop/STT TTS/notebook_data_trump speech_1.wav\"\n",
    "\n",
    "# use the audio file as the audio source\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source)  # read the entire audio file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sphinx\n",
    "\n",
    "Sphinx is a tool that makes it easy to create intelligent and beautiful documentation for Python projects (or other documents consisting of multiple reStructuredText sources).\n",
    "\n",
    "#### Installation\n",
    "Sphinx is published on PyPI and can be installed from there:\n",
    "\n",
    "**pip install -U sphinx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx error; missing PocketSphinx module: ensure that PocketSphinx is set up correctly.\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Sphinx\n",
    "\n",
    "try:\n",
    "    print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Google speech recognition\n",
    "\n",
    "The audio is recorded using the speech recognition module, the module will include on top of the program. \n",
    "\n",
    "Secondly we send the record speech to the Google speech recognition API which will then return the output.\n",
    "r.recognize_google(audio) returns a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text from audio is:\n",
      "my administration is more than most any administration in the history of America as usual meaning of the rest of the world I like it I like it only give respect us and our friends come here to this place for people and their\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Google Speech Recognition (default without credentials)   \n",
    "try:\n",
    "    print(\"The text from audio is:\\n\" + r.recognize_google(audio))\n",
    "except:\n",
    "    print(\"There was error processing audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Houndify \n",
    "\n",
    "Houndify offers an easy way for developers to use the platform for its speech to text capabilities via the Speech to Text Only domain.\n",
    "\n",
    "\n",
    "#### Creating a Client that uses Speech-to-Text\n",
    "- Click on the New Client button from your dashboard.\n",
    "- Give your client a unique name. We’ll call ours “Speech-to-Text Test Client”.\n",
    "- Click Save & Continue.\n",
    "- In the Domain Selection page, search for the “Speech to Text Only Domain” and enable it. Do not enable any other domains.\n",
    "- Click Save & Continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was error processing audio\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Houndify\n",
    "HOUNDIFY_CLIENT_ID = \"K-PDcIt1-UIYGmwLbe19mg==\"  \n",
    "HOUNDIFY_CLIENT_KEY = \"glsGO73hcZPBgdQ8toWXkGSsqS-lqcQyPTyxd71CsF3byCrG-0uRhx4D5cY4ulTOfSCVXGMSyVvordcxiBLFJA==\"\n",
    "\n",
    "try:\n",
    "    print(\"The text from audio is:\\n\" + r.recognize_houndify(audio, client_id=HOUNDIFY_CLIENT_ID, client_key=HOUNDIFY_CLIENT_KEY))\n",
    "except:\n",
    "    print(\"There was error processing audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Text to Speech conversions using different API's\n",
    "\n",
    "It can also be done using other API's\n",
    "<ul>\n",
    "    <li>recognize_bing():    Microsoft Bing Speech</li>\n",
    "    <li>recognize_google_cloud():   Google Cloud</li>\n",
    "    <li>recognize_ibm():    IBM Speech to Text</li>\n",
    "    <li>recognize_wit():    Wit.ai</li>\n",
    "</ul> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gTTS in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: six in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from gTTS) (1.10.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from gTTS) (0.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from gTTS) (6.7)\n",
      "Requirement already satisfied: requests in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from gTTS) (2.18.4)\n",
      "Requirement already satisfied: gtts_token in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from gTTS) (1.1.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from bs4->gTTS) (4.4.1)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from requests->gTTS) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from requests->gTTS) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from requests->gTTS) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (from requests->gTTS) (2018.4.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (0.2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wave in c:\\users\\31072\\appdata\\local\\enthought\\canopy\\edm\\envs\\user\\lib\\site-packages (0.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!pip install gTTS\n",
    "!pip install pyaudio\n",
    "!pip install wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Google Text to Speech\n",
    "\n",
    "gTTS is a very easy to use tool which converts the text entered, into audio which can be saved as a mp3 file.\n",
    "\n",
    "The gTTS API supports several languages including English, Hindi, Tamil, French, German and many more. The speech can be delivered in any one of the two available audio speeds, fast or slow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS \n",
    "import os \n",
    "  \n",
    "mytext = 'Welcome to Indian School of Business!'\n",
    "  \n",
    "# Language in which you want to convert \n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "myobj.save(\"welcome.mp3\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using Microphone as an input\n",
    "\n",
    " ## Recognition of Spoken Words\n",
    " \n",
    " \n",
    "Speech recognition means that when humans are speaking, a machine understands it. Here we are using Google Speech API in Python to make it happen. We need to install the following packages for this −\n",
    "\n",
    "-  Pyaudio − It can be installed by using **pip install Pyaudio command.**\n",
    "\n",
    "-  SpeechRecognition − This package can be installed by using **pip install SpeechRecognition.**\n",
    "\n",
    "-  Google-Speech-API − It can be installed by using the command  **pip install google-api-python-client.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n",
      "Could not open requirements file: [Errno 2] No such file or directory: 'anaconda'\n",
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n",
      "Could not open requirements file: [Errno 2] No such file or directory: 'conda-forge'\n",
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n",
      "Could not open requirements file: [Errno 2] No such file or directory: 'conda-forge'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!pip install -c anaconda pyaudio\n",
    "!pip install -c conda-forge speechrecognition \n",
    "!pip install -c conda-forge google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now Let us import the Speech_recognition package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A liberary known as **Recognizer()** is used to take in the voice input.\n",
    "\n",
    "The energy_threshold means that minimum 2500 voice is required for recognition(it may vary from 500 to 4000 or even more depending upon the microphone in use).\n",
    "\n",
    "The energy_threshold value is set to 300 by default. Under 'ideal' conditions (such as in a quiet room), values between 0 and 100 are considered silent or ambient, and values 300 to about 3500 are considered speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Recognizing the speech using microphone\n",
    "r = sr.Recognizer()\n",
    "r.energy_threshold = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With source as **Microphone** take in the voice input, using **listen()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "PyAudio 0.2.11 or later is required (found version 0.2.4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f61d3e9c9cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Input your speech by listen(_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Say Something:!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\31072\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\speech_recognition\\__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, device_index, sample_rate, chunk_size)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# set up PyAudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pyaudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\31072\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\speech_recognition\\__init__.pyc\u001b[0m in \u001b[0;36mget_pyaudio\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyaudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"0.2.11\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PyAudio 0.2.11 or later is required (found version {})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyaudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: PyAudio 0.2.11 or later is required (found version 0.2.4)"
     ]
    }
   ],
   "source": [
    "#Input your speech by listen(_)\n",
    "with sr.Microphone() as source:\n",
    "    print('Say Something:!')\n",
    "    audio = r.listen(source)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using google API to translate voice to text.\n",
    "\n",
    "Here by using the below link for language code use can convert any language voice into text.\n",
    "\n",
    "[LANGUAGE CODE:  ](https://cloud.google.com/speech-to-text/docs/languages)\n",
    "\n",
    "https://cloud.google.com/speech-to-text/docs/languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   print(\"You said: \\n\" + r.recognize_google(audio, language = 'hi-IN'))\n",
    "except Exception as e:\n",
    "   print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
