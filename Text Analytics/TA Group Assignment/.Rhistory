value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
runApp('~/Dropbox/isb/Term1/Text Analytics')
runApp('~/Dropbox/isb/Term1/Text Analytics')
runApp('~/Dropbox/isb/Term1/Text Analytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
library(shinythemes)
try(require(shinythemes) || install.packages("shinythemes"))
install.packages("shinythemes")
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
devtools::install_github("rstudio/r2d3")
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/Desktop/Temo.R')
runApp('~/Desktop/Temo.R')
InputDocument = readLines("Donald Trump.txt")
#Deriving the Annotated Data from a Document
#Installing the required packages
if (!require(udpipe)){install.packages("udpipe")}
if (!require(textrank)){install.packages("textrank")}
if (!require(lattice)){install.packages("lattice")}
if (!require(igraph)){install.packages("igraph")}
if (!require(ggraph)){install.packages("ggraph")}
if (!require(wordcloud)){install.packages("wordcloud")}
library(udpipe)
library(textrank)
library(lattice)
library(igraph)
library(ggraph)
library(ggplot2)
library(wordcloud)
library(stringr)
require(stringr)
InputDocument = readLines("Donald Trump.txt")
CleanDocument  =  str_replace_all(InputDocument, "<.*?>", "")
str(CleanDocument)
# load english model for annotation from working dir
english_model = udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")  # file_model only needed
# now annotate text dataset using ud_model above
x <- udpipe_annotate(english_model, x = CleanDocument)
Annotated_Data <- as.data.frame(x)
print(Annotated_Data)
#	})  # 13.76 secs
head(Annotated_Data, 4)
table(Annotated_Data$xpos)  # std penn treebank based POStags
table(Annotated_Data$upos)  # UD based postags
# So what're the most common nouns? verbs?
all_nouns = Annotated_Data %>% subset(., upos %in% "NOUN")
top_nouns = txt_freq(all_nouns$lemma)  # txt_freq() calcs noun freqs in desc order
head(top_nouns, 10)
all_verbs = Annotated_Data %>% subset(., upos %in% "VERB")
top_verbs = txt_freq(all_verbs$lemma)
head(top_verbs, 10)
all_propn = Annotated_Data %>% subset(., upos %in% "PROPN")
top_propn = txt_freq(all_propn$lemma)
head(top_propn, 10)
all_adverb = Annotated_Data %>% subset(., upos %in% "ADV")
top_adverb = txt_freq(all_adverb$lemma)
head(top_adverb, 10)
all_verb = Annotated_Data %>% subset(., upos %in% "VERB")
top_verb = txt_freq(all_verb$lemma)
head(top_verb, 10)
wordcloud(words = all_nouns$key,
freq = all_nouns$freq,
min.freq = 2,
max.words = 100,
random.order = FALSE,
colors = brewer.pal(6, "Dark2"))
wordcloud(words = all_verbs$key,
freq = all_verbs$freq,
min.freq = 2,
max.words = 100,
random.order = FALSE,
colors = brewer.pal(6, "Dark2"))
# Collocation (words following one another)
document_colloc <- keywords_collocation(x = Annotated_Data,   # try ?keywords_collocation
term = "token",
group = c("doc_id", "paragraph_id", "sentence_id"),
ngram_max = 4)  # 0.42 secs
str(document_colloc)
document_colloc %>% head()
# Co-occurrences based on selection this has to change
document_cooc <- cooccurrence(
x = subset(Annotated_Data, upos %in% c("NOUN", "ADJ")), #IF condition has to be added for selection
term = "lemma",
group = c("doc_id", "paragraph_id", "sentence_id"))  # 0.02 secs
head(document_cooc)
# general (non-sentence based) Co-occurrences
document_cooc_gen <- cooccurrence(x = Annotated_Data$lemma,
relevant = x$upos %in% c("NOUN", "ADJ")) # 0.00 secs
head(document_cooc_gen)
# Skipgram based Co-occurrences: How frequent do words follow one another within skipgram number of words
document_cooc_skipgm <- cooccurrence(x = x$lemma,
relevant = x$upos %in% c("NOUN", "ADJ"),
skipgram = 4)  # 0.05 secs
head(document_cooc_skipgm)  # sorted in descending order
wordnetwork <- head(document_cooc, 30)
wordnetwork <- igraph::graph_from_data_frame(wordnetwork) # needs edgelist in first 2 colms.
ggraph(wordnetwork, layout = "fr") +
geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "orange") +
geom_node_text(aes(label = name), col = "darkgreen", size = 4) +
theme_graph(base_family = "Arial Narrow") +
theme(legend.position = "none") +
labs(title = "Cooccurrences within 3 words distance", subtitle = "Nouns & Adjective")
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
## Only run examples in interactive R sessions
if (interactive()) {
ui <- fluidPage(
sidebarLayout(
sidebarPanel(
fileInput("file1", "Choose CSV File",
accept = c(
"text/csv",
"text/comma-separated-values,text/plain",
".csv")
),
tags$hr(),
checkboxInput("header", "Header", TRUE)
),
mainPanel(
tableOutput("contents")
)
)
)
server <- function(input, output) {
output$contents <- renderTable({
# input$file1 will be NULL initially. After the user selects
# and uploads a file, it will be a data frame with 'name',
# 'size', 'type', and 'datapath' columns. The 'datapath'
# column will contain the local filenames where the data can
# be found.
inFile <- input$file1
if (is.null(inFile))
return(NULL)
read.csv(inFile$datapath, header = input$header)
})
}
shinyApp(ui, server)
}
## Only run examples in interactive R sessions
if (interactive()) {
ui <- fluidPage(
sidebarLayout(
sidebarPanel(
fileInput("file1", "Choose CSV File",
accept = c(
"text/csv",
"text/comma-separated-values,text/plain",
".csv")
),
tags$hr(),
checkboxInput("header", "Header", TRUE)
),
mainPanel(
tableOutput("contents")
)
)
)
server <- function(input, output) {
output$contents <- renderTable({
# input$file1 will be NULL initially. After the user selects
# and uploads a file, it will be a data frame with 'name',
# 'size', 'type', and 'datapath' columns. The 'datapath'
# column will contain the local filenames where the data can
# be found.
inFile <- input$file1
if (is.null(inFile))
return(NULL)
read.csv(inFile$datapath, header = input$header)
})
}
shinyApp(ui, server)
}
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
try(require("shiny")||install.packages("shiny"))
try(require("nFactors")||install.packages("nFactors"))
try(require("qgraph")||install.packages("qgraph"))
try(require("corrplot")||install.packages("corrplot"))
library("shiny")
library("nFactors")
library("qgraph")
library("corrplot")
if (!require(udpipe)){install.packages("udpipe")}
if (!require(textrank)){install.packages("textrank")}
if (!require(lattice)){install.packages("lattice")}
if (!require(igraph)){install.packages("igraph")}
if (!require(ggraph)){install.packages("ggraph")}
if (!require(wordcloud)){install.packages("wordcloud")}
library(udpipe)
library(textrank)
library(lattice)
library(igraph)
library(ggraph)
library(ggplot2)
library(wordcloud)
library(stringr)
getwd()
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
library(shiny)
# Define UI for data upload app ----
ui <- fluidPage(
# App title ----
titlePanel("Uploading Files"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Select a file ----
fileInput("file1", "Choose CSV File",
multiple = TRUE,
accept = c("text/csv",
"text/comma-separated-values,text/plain",
".csv")),
# Horizontal line ----
tags$hr(),
# Input: Checkbox if file has header ----
checkboxInput("header", "Header", TRUE),
# Input: Select separator ----
radioButtons("sep", "Separator",
choices = c(Comma = ",",
Semicolon = ";",
Tab = "\t"),
selected = ","),
# Input: Select quotes ----
radioButtons("quote", "Quote",
choices = c(None = "",
"Double Quote" = '"',
"Single Quote" = "'"),
selected = '"'),
# Horizontal line ----
tags$hr(),
# Input: Select number of rows to display ----
radioButtons("disp", "Display",
choices = c(Head = "head",
All = "all"),
selected = "head")
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Data file ----
tableOutput("contents")
)
)
)
# Define server logic to read selected file ----
server <- function(input, output) {
output$contents <- renderTable({
# input$file1 will be NULL initially. After the user selects
# and uploads a file, head of that data file by default,
# or all rows if selected, will be shown.
req(input$file1)
df <- read.csv(input$file1$datapath,
header = input$header,
sep = input$sep,
quote = input$quote)
if(input$disp == "head") {
return(head(df))
}
else {
return(df)
}
})
}
# Run the app ----
shinyApp(ui, server)
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/Test')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
runApp('~/OneDrive - Indian School of Business/Text Analytics/TextAnalytics')
annotated_text <-
udpipe_annotate(model, x = temp)
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
doc <- readLines("Donald Trump.txt")
temp <- tolower(doc) #convert to lowercase
temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ") #remove all non alphabets
temp <- stringr::str_replace_all(temp,"[\\s]+", " ")  #strip extra spaces
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
annotated_text <-
udpipe_annotate(model, x = temp)
annotated_df <- as.data.frame(annotated_text)
doc <- readLines("Donald Trump.txt")
setwd("~/OneDrive - Indian School of Business/Text Analytics")
temp <- tolower(doc) #convert to lowercase
doc <- readLines("Donald Trump.txt")
temp <- tolower(doc) #convert to lowercase
temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ") #remove all non alphabets
temp <- stringr::str_replace_all(temp,"[\\s]+", " ")  #strip extra spaces
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
setwd("~/OneDrive - Indian School of Business/Text Analytics")
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
doc <- readLines("Donald Trump.txt")
temp <- tolower(doc) #convert to lowercase
temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ") #remove all non alphabets
temp <- stringr::str_replace_all(temp,"[\\s]+", " ")  #strip extra spaces
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
annotated_text <-
udpipe_annotate(model, x = temp)
annotated_df <- as.data.frame(annotated_text)
doc <- readLines("Donald Trump.txt")
temp <- tolower(doc) #convert to lowercase
temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ") #remove all non alphabets
temp <- stringr::str_replace_all(temp,"[\\s]+", " ")  #strip extra spaces
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
#model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
annotated_text <-
udpipe_annotate(ud_model, x = temp)
annotated_df <- as.data.frame(annotated_text)
View(annotated_df)
runApp('TextAnalytics')
noun_doc = subset(annotated_df, upos = 'NOUN')
top_nouns = txt_freq(noun_doc$lemma)
View(top_nouns)
View(top_nouns)
runApp('TextAnalytics')
View(annotated_df)
colnames(annotated_df)
runApp('TextAnalytics')
install.packages("DT")
shiny::runApp('TextAnalytics')
runApp('TextAnalytics')
runApp('TextAnalytics')
runApp('TextAnalytics')
try(require(shiny) || install.packages("shiny"))
try(require(shinythemes) || install.packages("shinythemes"))
try(require(text2vec) || install.packages("text2vec"))
try(require(tm) || install.packages("tm"))
try(require(tokenizers) || install.packages("tokenizers"))
try(require(wordcloud) || install.packages("wordcloud"))
try(require(slam) || install.packages("slam"))
try(require(stringi) || install.packages("stringi"))
try(require(magrittr) || install.packages("magrittr"))
try(require(tidytext) || install.packages("tidytext"))
try(require(dplyr) || install.packages("dplyr"))
try(require(tidyr) || install.packages("tidyr"))
try(require(igraph)|| install.packages("igraph"))
try(require(udpipe) || install.packages("udpipe"))
try(require(textrank) || install.packages("textrank"))
try(require(lattice) || install.packages("lattice"))
try(require(ggraph) || install.packages("ggraph"))
#devtools::install_github("rstudio/r2d3")
library(shiny)
library(shinythemes)
library(text2vec)
library(tm)
library(tokenizers)
library(wordcloud)
library(slam)
library(stringi)
library(magrittr)
library(tidytext)
library(dplyr)
library(tidyr)
library(igraph)
library(udpipe)
library(textrank)
library(lattice)
library(ggraph)
runApp('TextAnalytics')
runApp('TextAnalytics')
shiny::runApp('TextAnalytics')
library(shiny)
library(shinythemes)
#library(text2vec)
#library(tm)
#library(tokenizers)
library(wordcloud)
#library(slam)
#library(stringi)
#library(magrittr)
#library(tidytext)
#library(dplyr)
#library(tidyr)
#library(igraph)
library(udpipe)
#library(textrank)
#library(lattice)
#library(ggraph)
runApp('TextAnalytics')
library(ggraph)
runApp('TextAnalytics')
if (!require(shiny)) {install.packages("shiny")}
if (!require(shinythemes)) {install.packages("shinythemes")}
if (!require(wordcloud)) {install.packages("wordcloud")}
if (!require(udpipe)) {install.packages("udpipe")}
if (!require(ggraph)) {install.packages("ggraph")}
if (!require(igraph)) {install.packages("igraph")}
if (!require(stringr)) {install.packages("stringr")}
library(shiny)
library(shinythemes)
library(wordcloud)
library(udpipe)
library(ggraph)
library(igraph)
library(stringr)
runApp('TextAnalytics')
runApp('TextAnalytics')
doc <- readLines("Donald Trump.txt")
temp <- tolower(doc) #convert to lowercase
temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ") #remove all non alphabets
temp <- stringr::str_replace_all(temp,"[\\s]+", " ")  #strip extra spaces
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
#model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
annotated_text <-
udpipe_annotate(ud_model, x = temp)
runApp('TextAnalytics')
runApp('TextAnalytics')
#model <- udpipe_load_model("english-ewt-ud-2.4-190531.udpipe")
annotated_text <-
udpipe_annotate(ud_model, x = temp)
annotated_df <- as.data.frame(annotated_text)
drop_sentence <- c("sentence")
display_df <- annotated_df[ , c("sentence")]
display_df <- subset(annotated_df, select = -c('sentence'))
display_df <- subset(annotated_df, -c('sentence'))
display_df <- subset(annotated_df, -c(sentence))
display_df <- annotated_df[, -c(sentence)]
display_df <- annotated_df[, -c('sentence')]
View(annotated_df)
display_df <- subset(annotated_df, select=-c(sentence))
View(display_df)
display_top_100 <- head(display_df, 100)
View(display_top_100)
runApp('TextAnalytics')
runApp('TextAnalytics')
runApp('TextAnalytics')
runApp('TextAnalytics')
