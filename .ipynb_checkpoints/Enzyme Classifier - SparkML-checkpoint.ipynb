{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shubhendu Vimal - 11915067\n",
    "\n",
    "- Dharani Kiran Kavuri - 11915033\n",
    "\n",
    "- Anmol More - 11915043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> ReadMe :</H2>\n",
    "\n",
    "- Data Preparation through python script\n",
    "- Convert raw data csv and then to libsvm in R\n",
    "- Run spark ML algos in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, OneVsRest\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Read data </H2>\n",
    "<H4> Read cleaned and processed data for enzymes from data directory </H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File : data/uniprot-Oxidoreductases.csv\n",
      "(89604, 24)\n",
      "Processing File : data/uniprot-Isomerase.csv\n",
      "(100001, 24)\n",
      "Processing File : data/uniprot-Hydrolases.csv\n",
      "(100001, 24)\n",
      "Processing File : data/uniprot-ligase.csv\n",
      "(100001, 24)\n",
      "Processing File : data/uniprot-Lyase.csv\n",
      "(100001, 24)\n",
      "Processing File : data/uniprot-Transferases.csv\n",
      "(100001, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>T</th>\n",
       "      <th>Type</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>Y</th>\n",
       "      <th>gravy</th>\n",
       "      <th>weight</th>\n",
       "      <th>type_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334374</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MGRTDDMLIIRGVNVFPSQIESVLLENGDTTPHYQLIVNRKGNLDD...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uniprot-ligase</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.410577</td>\n",
       "      <td>11844.5304</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447198</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MPHRILVLHGPNLNLLGTREPEVYGRTTLADIDAALTAQAQTAGAE...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniprot-Lyase</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>15959.8291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329103</th>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MVHELLQQAKWRIIDQSHFGPMFDAKQSFAIDDTLCTSVGKGLSDP...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>uniprot-ligase</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.012950</td>\n",
       "      <td>31174.5785</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215190</th>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MFDIGVNLTSTQFAKDRDKVVKRAREAGISGMLITGTNALESQQAL...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>uiprot-Hydrolases</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.122394</td>\n",
       "      <td>28765.5914</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92571</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>MKLSFNTWVYNSFPSMLPFYPLEEVISRIAAFGYDGIEIGCASPHA...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniprot-Isomerase</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.422857</td>\n",
       "      <td>31818.8477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A    C     D     E     F     G    H     I     K     L  ...     S  \\\n",
       "334374   2.0  0.0   5.0  12.0   2.0   7.0  1.0  10.0   7.0  10.0  ...   7.0   \n",
       "447198  22.0  1.0   7.0   7.0   6.0  14.0  8.0  10.0   0.0  14.0  ...   6.0   \n",
       "329103  18.0  3.0  12.0  15.0  11.0  21.0  5.0  19.0  16.0  33.0  ...  24.0   \n",
       "215190  31.0  7.0  11.0  19.0  10.0  14.0  8.0  11.0   5.0  35.0  ...  14.0   \n",
       "92571   22.0  4.0  19.0  20.0  10.0  20.0  8.0  15.0  22.0  25.0  ...  17.0   \n",
       "\n",
       "                                                 Sequence     T  \\\n",
       "334374  MGRTDDMLIIRGVNVFPSQIESVLLENGDTTPHYQLIVNRKGNLDD...   5.0   \n",
       "447198  MPHRILVLHGPNLNLLGTREPEVYGRTTLADIDAALTAQAQTAGAE...   9.0   \n",
       "329103  MVHELLQQAKWRIIDQSHFGPMFDAKQSFAIDDTLCTSVGKGLSDP...  13.0   \n",
       "215190  MFDIGVNLTSTQFAKDRDKVVKRAREAGISGMLITGTNALESQQAL...  14.0   \n",
       "92571   MKLSFNTWVYNSFPSMLPFYPLEEVISRIAAFGYDGIEIGCASPHA...   9.0   \n",
       "\n",
       "                     Type     V    W     Y     gravy      weight  type_numeric  \n",
       "334374     uniprot-ligase  10.0  0.0   1.0 -0.410577  11844.5304             2  \n",
       "447198      uniprot-Lyase  11.0  1.0   5.0  0.094595  15959.8291             1  \n",
       "329103     uniprot-ligase  21.0  4.0  13.0 -0.012950  31174.5785             2  \n",
       "215190  uiprot-Hydrolases  13.0  5.0   2.0 -0.122394  28765.5914             4  \n",
       "92571   uniprot-Isomerase  15.0  8.0  14.0 -0.422857  31818.8477             0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "files = glob.glob(\"data/*.csv\")\n",
    "for file in files :\n",
    "    print(\"Processing File :\", file)\n",
    "    df = pd.read_csv(file)\n",
    "    print(df.shape)\n",
    "    data = data.append(df, ignore_index=True)\n",
    "     \n",
    "\n",
    "def type_to_numeric(x):\n",
    "    if x=='uniprot-Isomerase':\n",
    "        return 0\n",
    "    if x=='uniprot-Lyase':\n",
    "        return 1\n",
    "    if x=='uniprot-ligase':\n",
    "        return 2\n",
    "    if x=='uniprot-Transferases' :\n",
    "        return 3\n",
    "    if x=='uiprot-Hydrolases' :\n",
    "        return 4\n",
    "    if x=='uniprot-Oxidoreductases' :\n",
    "        return 5\n",
    "    \n",
    "data['type_numeric'] = data['Type'].apply(type_to_numeric) \n",
    "\n",
    "#Final csv to work upon and run spark ML algorithms\n",
    "#Taking 100000 records of each enzyme\n",
    "data.to_csv(\"final_data/protien-sequences.csv\", index=False)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> R Code </H2>\n",
    "<H4> Convert csv data to libsvm for sparkML </H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: e1071\n",
      "\n",
      "R[write to console]: Loading required package: SparseM\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘SparseM’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    backsolve\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# Ref : https://vatsalbits.wordpress.com/2016/01/13/csv-to-libsvm/\n",
    "\n",
    "# download e1071 library if not available\n",
    "if (!require(e1071)) {install.packages(\"e1071\")}\n",
    "\n",
    "# download sparseM library if not available\n",
    "if (!require(SparseM)) {install.packages(\"SparseM\")}\n",
    "\n",
    "# load the libraries\n",
    "library(e1071)\n",
    "library(SparseM)\n",
    "\n",
    "# load the csv dataset into memory\n",
    "data <- read.csv('final_data/protien-sequences.csv')\n",
    "\n",
    "# take the numeric columns are format as matrix\n",
    "x <- as.matrix(data[,c('A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M',\n",
    "                       'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', \n",
    "                       'gravy', 'weight')])\n",
    "# assign labels to vector y\n",
    "y <- data[,'type_numeric']\n",
    "\n",
    "# convert input columns to sparse matrix\n",
    "x_matrix <- as.matrix.csr(x)\n",
    "\n",
    "# write output to libsvm format\n",
    "write.matrix.csr(x_matrix, y=y, file=\"final_data/protien-sequences-libsvm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new spark session\n",
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder.appName('protien-classifier').\n",
    "config(\"spark.executor.memory\", MAX_MEMORY).\n",
    "config(\"spark.driver.memory\", MAX_MEMORY).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\").load(\"final_data/protien-sequences-libsvm.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Run Spark-MLlib Algorithms\n",
    "   \n",
    "<H3> Logistic Regression Classifier</H3>\n",
    "\n",
    "Code chunks are directly taken from official spark-ml documentation.\n",
    "\n",
    "Ref - https://spark.apache.org/docs/latest/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Reg Coefficients: DenseMatrix([[ 5.45202991e-03, -8.41721306e-02,  1.47792590e-02,\n",
      "               3.31893586e-03, -3.73312494e-04, -9.73336894e-04,\n",
      "              -1.93253095e-02, -5.61266461e-03,  2.89474262e-02,\n",
      "               3.58842586e-03,  6.87395544e-04, -1.34753590e-03,\n",
      "              -2.70238535e-03,  1.24997026e-02,  3.13580444e-04,\n",
      "              -6.59144958e-03,  1.79010417e-03, -1.75218553e-03,\n",
      "              -1.02059722e-01, -1.99632503e-02, -8.86660848e-01,\n",
      "               8.33571514e-07],\n",
      "             [ 8.85022716e-03, -1.18602161e-02,  2.83949155e-03,\n",
      "              -4.75651902e-03, -1.67761010e-02,  3.44992374e-03,\n",
      "              -2.00237860e-02, -3.42373036e-03, -1.04233788e-02,\n",
      "               1.00570350e-03,  9.45213109e-03,  2.87557424e-02,\n",
      "              -0.00000000e+00,  4.38811521e-03, -3.17804872e-03,\n",
      "               7.87092740e-03,  1.46965982e-02, -3.95256967e-03,\n",
      "              -3.74618000e-02, -7.53803470e-03,  1.78657822e-01,\n",
      "               1.01338335e-06],\n",
      "             [-5.44382414e-04, -3.65995056e-02,  1.58249042e-02,\n",
      "               2.90505556e-02,  1.97166963e-02, -2.58209170e-03,\n",
      "              -2.72139077e-02, -3.92640394e-03,  1.39468558e-02,\n",
      "               6.41660339e-03, -4.90823743e-03, -1.22397775e-02,\n",
      "              -2.10386699e-03, -2.55006639e-03,  3.58658471e-04,\n",
      "              -9.47427993e-03, -3.44740078e-03, -1.08598272e-03,\n",
      "               2.32355489e-02,  1.23598495e-02, -1.95403376e-01,\n",
      "              -1.24076148e-06],\n",
      "             [-2.03297917e-02,  1.21864343e-02, -1.58565824e-02,\n",
      "              -2.09937573e-02, -1.88554774e-02,  6.02781399e-03,\n",
      "               2.04237107e-02,  8.34704605e-02,  2.49272055e-03,\n",
      "              -3.20490486e-02, -6.43147253e-02,  7.89723454e-03,\n",
      "              -7.28943716e-03, -9.92204577e-03,  2.17382198e-03,\n",
      "              -7.46535750e-04, -1.25944695e-02,  2.74750585e-02,\n",
      "               1.58983343e-02, -0.00000000e+00,  1.12359426e+00,\n",
      "              -3.18344785e-07],\n",
      "             [-2.45574514e-03,  2.79102499e-02,  1.62842341e-03,\n",
      "              -4.20275874e-03,  3.90743498e-03, -2.62320748e-03,\n",
      "               6.86609432e-02, -6.35138103e-03, -4.75216675e-03,\n",
      "               1.00420738e-03,  1.78526063e-02, -2.75581708e-03,\n",
      "               7.65353346e-04, -5.89824624e-03, -3.73230530e-04,\n",
      "               1.84585536e-02,  1.37432514e-03, -7.31473093e-03,\n",
      "              -4.08326154e-03,  1.26975951e-02, -5.71198888e-02,\n",
      "               4.24723852e-07],\n",
      "             [-7.61661945e-04,  1.22353827e-01, -1.39996583e-02,\n",
      "              -9.55126011e-03,  8.01425588e-03, -3.50855993e-03,\n",
      "               8.79739093e-03, -1.08732097e-02, -9.43516283e-03,\n",
      "               0.00000000e+00,  1.20510455e-03, -7.56656920e-03,\n",
      "               7.07526911e-03,  6.41561717e-03, -7.95823268e-04,\n",
      "               2.42710127e-04, -4.77668365e-03, -6.11424855e-03,\n",
      "               3.65983003e-02,  6.71549501e-04, -3.34873437e-01,\n",
      "              -6.77072976e-07]])\n",
      "Logistic Reg Intercept: [0.17462809241234534,0.010481053067311924,-0.6559807909752295,0.5357280943220546,-0.48115648566839414,0.41630003684191186]\n",
      "Model accuracy : 0.36205831255588106\n",
      "False positive rate : 0.12731148458569602\n",
      "True positive rate : 0.36205831255588106\n",
      "F-measure : 0.3611527231912624\n",
      "Precision : 0.3628963004678636\n",
      "Recall : 0.36205831255588106\n",
      "CPU times: user 21.3 ms, sys: 6.57 ms, total: 27.8 ms\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#split dataset in test and training sets\n",
    "(train, test) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "#use max iteration of 10, and few default parameters\n",
    "logistic_reg = LogisticRegression(maxIter=20, regParam=0.005, \n",
    "                                  elasticNetParam=0.005)\n",
    "\n",
    "# Fit the model\n",
    "logic_reg_model = logistic_reg.fit(train)\n",
    "\n",
    "# coefficients and intercept for multi class logistic regression\n",
    "print(\"Logistic Reg Coefficients: \" + str(logic_reg_model.coefficientMatrix))\n",
    "print(\"Logistic Reg Intercept: \" + str(logic_reg_model.interceptVector))\n",
    "\n",
    "# Print model summary\n",
    "model_summary = logic_reg_model.summary\n",
    "\n",
    "accuracy = str(model_summary.accuracy)\n",
    "false_positive_rate = str(model_summary.weightedFalsePositiveRate)\n",
    "true_positive_rate = str(model_summary.weightedTruePositiveRate)\n",
    "f_measure = str(model_summary.weightedFMeasure())\n",
    "precision = str(model_summary.weightedPrecision)\n",
    "recall = str(model_summary.weightedRecall)\n",
    "\n",
    "print(\"Model accuracy : \" + accuracy +\n",
    "      \"\\nFalse positive rate : \" + false_positive_rate +\n",
    "      \"\\nTrue positive rate : \" + true_positive_rate +\n",
    "      \"\\nF-measure : \" + f_measure +\n",
    "      \"\\nPrecision : \" + precision +\n",
    "      \"\\nRecall : \" + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Decision Tree Classifier </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created decision tree classifier with : \n",
      "\n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_62c948558ae8) of depth 5 with 51 nodes\n",
      "+----------+-----------+--------------------+\n",
      "|prediction|index_label|            features|\n",
      "+----------+-----------+--------------------+\n",
      "|       5.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       5.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       0.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       3.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       5.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       5.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       5.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       5.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       3.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "|       3.0|        5.0|(22,[0,1,2,3,4,5,...|\n",
      "+----------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Test set error = 0.651715 \n",
      "CPU times: user 41.3 ms, sys: 9.75 ms, total: 51.1 ms\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#mark labels as index of libsvm data\n",
    "label_index = StringIndexer(inputCol=\"label\", outputCol=\"index_label\").fit(data)\n",
    "\n",
    "# Mark all input columns as features\n",
    "feature_index = VectorIndexer(inputCol=\"features\", \n",
    "                              outputCol=\"index_features\", \n",
    "                              maxCategories=2).fit(data)\n",
    "\n",
    "# Lets do 60:40 ratio for training and test data\n",
    "(train, test) = data.randomSplit([0.6, 0.4])\n",
    "\n",
    "# Make a decision tree model\n",
    "decision_tree_classifier = DecisionTreeClassifier(labelCol=\"index_label\", \n",
    "                                                  featuresCol=\"index_features\")\n",
    "\n",
    "# Create a pipeline of decision tree model\n",
    "pipeline = Pipeline(stages=[label_index, feature_index, decision_tree_classifier])\n",
    "\n",
    "# train our decision tree using input columns\n",
    "decision_tree_model = pipeline.fit(train)\n",
    "\n",
    "model_summary = decision_tree_model.stages[2]\n",
    "# summary only\n",
    "print(\"Created decision tree classifier with : \\n\")\n",
    "print(model_summary)\n",
    "\n",
    "# Get predictions for test set\n",
    "predictions_test = decision_tree_model.transform(test)\n",
    "\n",
    "# Look at top 10 predictions, 9/10 predictions seems correct\n",
    "predictions_test.select(\"prediction\", \"index_label\", \"features\").show(10)\n",
    "\n",
    "# calculate accurancy on test set\n",
    "multi_class_classification_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"index_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_percentage = multi_class_classification_evaluator.evaluate(predictions_test)\n",
    "\n",
    "print(\"Test set error = %f \" % (1.0 - accuracy_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Random Forest Classifier </H3>\n",
    "\n",
    "As per our evaluation, this gives us best result with accuracy of 57% with 30 trees\n",
    "\n",
    "We can further work on this to increase number of trees, max depth and other hyper parameter tunings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created random forest classifier with : \n",
      "\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_5f69f240db35) with 30 trees\n",
      "+---------------+-----+--------------------+\n",
      "|predicted_label|label|            features|\n",
      "+---------------+-----+--------------------+\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "|            5.0|  5.0|(22,[0,1,2,3,4,5,...|\n",
      "+---------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Test set error = 0.436635 \n",
      "CPU times: user 46 ms, sys: 11 ms, total: 57 ms\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#mark labels as index of libsvm data\n",
    "label_index = StringIndexer(inputCol=\"label\", outputCol=\"index_label\").fit(data)\n",
    "\n",
    "# Mark all input columns as features\n",
    "feature_index = VectorIndexer(inputCol=\"features\", outputCol=\"index_features\", \n",
    "                              maxCategories=2).fit(data)\n",
    "\n",
    "# Lets do 70:30 ratio for training and test data this time\n",
    "(train, test) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a random forest classifier with 20 trees\n",
    "random_forest_classifier = RandomForestClassifier(labelCol=\"index_label\", \n",
    "                                                  featuresCol=\"index_features\", \n",
    "                                                  numTrees=30, maxDepth=10)\n",
    "\n",
    "# label converter to convert indexed labels\n",
    "label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predicted_label\",\n",
    "                               labels=label_index.labels)\n",
    "\n",
    "# Create a pipeline of random forest model\n",
    "pipeline = Pipeline(stages=[label_index, feature_index, \n",
    "                            random_forest_classifier, label_converter])\n",
    "\n",
    "# Train random forest classifier\n",
    "random_forest_model = pipeline.fit(train)\n",
    "\n",
    "model_summary = random_forest_model.stages[2]\n",
    "# summary only\n",
    "print(\"Created random forest classifier with : \\n\")\n",
    "print(model_summary)\n",
    "\n",
    "# Get predictions for test set\n",
    "predictions_test = random_forest_model.transform(test)\n",
    "\n",
    "# see few of our predictions\n",
    "predictions_test.select(\"predicted_label\", \"label\", \"features\").show(10)\n",
    "\n",
    "# Calculate test set error\n",
    "multi_class_classification_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"index_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_percentage = multi_class_classification_evaluator.evaluate(predictions_test)\n",
    "\n",
    "print(\"Test set error = %f \" % (1.0 - accuracy_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>One-vs-Rest classifier (a.k.a. One-vs-All)</H3>\n",
    "\n",
    "Create classifier with multiple binary classifiers and combine\n",
    "\n",
    "Increasing number of iterations in this case doesn't affects accuracy beyond 39%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set error = 0.614291 \n",
      "CPU times: user 256 ms, sys: 58 ms, total: 314 ms\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#split train and test set in 80:20 ratio\n",
    "(train, test) = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# instantiate logistic regression classifier\n",
    "logistic_regression_classifier = LogisticRegression(maxIter=30, \n",
    "                                                    tol=1E-7, fitIntercept=True)\n",
    "\n",
    "# initializer our one vs rest classifier\n",
    "one_vs_rest = OneVsRest(classifier=logistic_regression_classifier)\n",
    "\n",
    "# train model on training data\n",
    "one_vs_rest_model = one_vs_rest.fit(train)\n",
    "\n",
    "# get predictions on test data\n",
    "test_predictions = one_vs_rest_model.transform(test)\n",
    "\n",
    "# Test accuracy using multi class evaluator\n",
    "multi_class_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "accuracy_percentage = multi_class_evaluator.evaluate(test_predictions)\n",
    "print(\"Test set error = %f \" % (1.0 - accuracy_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Feedforward Artificial Neural Network Classifier </H3>\n",
    "\n",
    "* References :\n",
    "\n",
    "- https://dzone.com/articles/deep-learning-via-multilayer-perceptron-classifier\n",
    "\n",
    "- https://spark.apache.org/docs/2.2.1/api/java/index.html?org/apache/spark/ml/classification/RandomForestClassifier.html\n",
    "\n",
    "Neural network test test accuracy calculation has some issues with library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 ms, sys: 6.53 ms, total: 37.9 ms\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#split data in 60:40 ratio\n",
    "random_split = data.randomSplit([0.6, 0.4])\n",
    "train = random_split[0]\n",
    "test = random_split[1]\n",
    "\n",
    "# specify input, middle, output layers\n",
    "# No of input layers - 20\n",
    "# intermediate layers - 15, 10, 8\n",
    "# output layers - 3\n",
    "layers = [20, 15, 10, 8, 6]\n",
    "\n",
    "# create multilayer neural network classifier\n",
    "nn_model = MultilayerPerceptronClassifier(maxIter=100, \n",
    "                                          layers=layers, blockSize=128)\n",
    "\n",
    "# train our neural network\n",
    "model = nn_model.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "test_predictions = model.transform(test)\n",
    "\n",
    "predictionAndLabels = test_predictions.select(\"prediction\", \"label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
