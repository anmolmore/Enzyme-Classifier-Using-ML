{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Speech to text conversions using different API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Hardik_pandya/Desktop/hp/speech_text_visa/notebook_data_trump speech_1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c7fd6164ee06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# use the audio file as the audio source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUDIO_FILE\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# read the entire audio file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\31072\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\speech_recognition\\__init__.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# attempt to read the file as WAV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m  \u001b[1;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\31072\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\wave.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\31072\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\wave.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# else, assume it is an open file object already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Hardik_pandya/Desktop/hp/speech_text_visa/notebook_data_trump speech_1.wav'"
     ]
    }
   ],
   "source": [
    "# obtain path to \"english.wav\" in the same folder as this script\n",
    "from os import path\n",
    "AUDIO_FILE = \"C:/Users/31072Desktop/notebook_data_trump speech_1.wav\"\n",
    "\n",
    "# use the audio file as the audio source\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source)  # read the entire audio file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sphinx\n",
    "\n",
    "Sphinx is a tool that makes it easy to create intelligent and beautiful documentation for Python projects (or other documents consisting of multiple reStructuredText sources).\n",
    "\n",
    "#### Installation\n",
    "Sphinx is published on PyPI and can be installed from there:\n",
    "\n",
    "**pip install -U sphinx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx error; missing PocketSphinx module: ensure that PocketSphinx is set up correctly.\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Sphinx\n",
    "\n",
    "try:\n",
    "    print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Google speech recognition\n",
    "\n",
    "The audio is recorded using the speech recognition module, the module will include on top of the program. \n",
    "\n",
    "Secondly we send the record speech to the Google speech recognition API which will then return the output.\n",
    "r.recognize_google(audio) returns a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text from audio is:\n",
      "my administration is more than most any administration in the history of America as usual meaning of the rest of the world I like it I like it only give respect us and our friends come here to this place for people and their\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Google Speech Recognition (default without credentials)   \n",
    "try:\n",
    "    print(\"The text from audio is:\\n\" + r.recognize_google(audio))\n",
    "except:\n",
    "    print(\"There was error processing audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Houndify \n",
    "\n",
    "Houndify offers an easy way for developers to use the platform for its speech to text capabilities via the Speech to Text Only domain.\n",
    "\n",
    "\n",
    "#### Creating a Client that uses Speech-to-Text\n",
    "- Click on the New Client button from your dashboard.\n",
    "- Give your client a unique name. We’ll call ours “Speech-to-Text Test Client”.\n",
    "- Click Save & Continue.\n",
    "- In the Domain Selection page, search for the “Speech to Text Only Domain” and enable it. Do not enable any other domains.\n",
    "- Click Save & Continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text from audio is:\n",
      "my administration has accomplished more than almost any administration in the history of our country america's center didn't expect that reaction but that's ok united states will not tell you how to live for work or worship we only ask that you honor our sovereignty in return i would like to thank chairman kim for his courage and for the steps he has taken though much work remains to be done our shared goals must be the de escalation of military conflict along with a political solution that honors the will of the syrian people the united states will respond if chemical weapons are deployed by the assad regime\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Houndify\n",
    "HOUNDIFY_CLIENT_ID = \"K-PDcIt1-UIYGmwLbe19mg==\"  \n",
    "HOUNDIFY_CLIENT_KEY = \"glsGO73hcZPBgdQ8toWXkGSsqS-lqcQyPTyxd71CsF3byCrG-0uRhx4D5cY4ulTOfSCVXGMSyVvordcxiBLFJA==\"\n",
    "\n",
    "try:\n",
    "    print(\"The text from audio is:\\n\" + r.recognize_houndify(audio, client_id=HOUNDIFY_CLIENT_ID, client_key=HOUNDIFY_CLIENT_KEY))\n",
    "except:\n",
    "    print(\"There was error processing audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Text to Speech conversions using different API's\n",
    "\n",
    "It can also be done using other API's\n",
    "<ul>\n",
    "    <li>recognize_bing():    Microsoft Bing Speech</li>\n",
    "    <li>recognize_google_cloud():   Google Cloud</li>\n",
    "    <li>recognize_ibm():    IBM Speech to Text</li>\n",
    "    <li>recognize_wit():    Wit.ai</li>\n",
    "</ul> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gTTS in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: six in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gTTS) (1.11.0)\n",
      "Requirement already satisfied: click in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gTTS) (6.7)\n",
      "Requirement already satisfied: requests in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gTTS) (2.18.4)\n",
      "Requirement already satisfied: gtts-token in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gTTS) (1.1.3)\n",
      "Requirement already satisfied: bs4 in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from gTTS) (0.0.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->gTTS) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->gTTS) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->gTTS) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests->gTTS) (2019.3.9)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from bs4->gTTS) (4.6.0)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.2.11)\n",
      "Requirement already satisfied: wave in c:\\users\\31153\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.0.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!pip install gTTS\n",
    "!pip install pyaudio\n",
    "!pip install wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Google Text to Speech\n",
    "\n",
    "gTTS is a very easy to use tool which converts the text entered, into audio which can be saved as a mp3 file.\n",
    "\n",
    "The gTTS API supports several languages including English, Hindi, Tamil, French, German and many more. The speech can be delivered in any one of the two available audio speeds, fast or slow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS \n",
    "import os \n",
    "  \n",
    "mytext = 'Welcome to Indian School of Business!'\n",
    "  \n",
    "# Language in which you want to convert \n",
    "language = 'en'\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "myobj.save(\"welcome.mp3\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using Microphone as an input\n",
    "\n",
    " ## Recognition of Spoken Words\n",
    " \n",
    " \n",
    "Speech recognition means that when humans are speaking, a machine understands it. Here we are using Google Speech API in Python to make it happen. We need to install the following packages for this −\n",
    "\n",
    "-  Pyaudio − It can be installed by using **pip install Pyaudio command.**\n",
    "\n",
    "-  SpeechRecognition − This package can be installed by using **pip install SpeechRecognition.**\n",
    "\n",
    "-  Google-Speech-API − It can be installed by using the command  **pip install google-api-python-client.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!conda install -c anaconda pyaudio\n",
    "!conda install -c conda-forge speechrecognition \n",
    "!conda install -c conda-forge google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now Let us import the Speech_recognition package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A liberary known as **Recognizer()** is used to take in the voice input.\n",
    "\n",
    "The energy_threshold means that minimum 2500 voice is required for recognition(it may vary from 500 to 4000 or even more depending upon the microphone in use).\n",
    "\n",
    "The energy_threshold value is set to 300 by default. Under 'ideal' conditions (such as in a quiet room), values between 0 and 100 are considered silent or ambient, and values 300 to about 3500 are considered speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Recognizing the speech using microphone\n",
    "r = sr.Recognizer()\n",
    "r.energy_threshold = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With source as **Microphone** take in the voice input, using **listen()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something:!\n"
     ]
    }
   ],
   "source": [
    "#Input your speech by listen(_)\n",
    "with sr.Microphone() as source:\n",
    "    print('Say Something:!')\n",
    "    audio = r.listen(source)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using google API to translate voice to text.\n",
    "\n",
    "Here by using the below link for language code use can convert any language voice into text.\n",
    "\n",
    "[LANGUAGE CODE:  ](https://cloud.google.com/speech-to-text/docs/languages)\n",
    "\n",
    "https://cloud.google.com/speech-to-text/docs/languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "   print(\"You said: \\n\" + r.recognize_google(audio, language = 'hi-IN'))\n",
    "except Exception as e:\n",
    "   print(e) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
