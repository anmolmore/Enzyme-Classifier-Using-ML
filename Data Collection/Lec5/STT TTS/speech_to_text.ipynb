{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Recognition of Spoken Words\n",
    " \n",
    " \n",
    "Speech recognition means that when humans are speaking, a machine understands it. Here we are using Google Speech API in Python to make it happen. We need to install the following packages for this −\n",
    "\n",
    "-  Pyaudio − It can be installed by using **pip install Pyaudio command.**\n",
    "\n",
    "-  SpeechRecognition − This package can be installed by using **pip install SpeechRecognition.**\n",
    "\n",
    "-  Google-Speech-API − It can be installed by using the command  **pip install google-api-python-client.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!conda install -c anaconda pyaudio\n",
    "!conda install -c conda-forge speechrecognition \n",
    "!conda install -c conda-forge google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let us import the Speech_recognition package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A liberary known as **Recognizer()** is used to take in the voice input.\n",
    "\n",
    "The energy_threshold means that minimum 2500 voice is required for recognition(it may vary from 500 to 4000 or even more depending upon the microphone in use).\n",
    "\n",
    "The energy_threshold value is set to 300 by default. Under 'ideal' conditions (such as in a quiet room), values between 0 and 100 are considered silent or ambient, and values 300 to about 3500 are considered speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognizing the speech using microphone\n",
    "r = sr.Recognizer()\n",
    "r.energy_threshold = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With source as **Microphone** take in the voice input, using **listen()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something:!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Input your speech by listen(_)\n",
    "with sr.Microphone() as source:\n",
    "    print('Say Something:!')\n",
    "    audio = r.listen(source)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using google API to translate voice to text.\n",
    "\n",
    "Here by using the below link for language code use can convert any language voice into text.\n",
    "\n",
    "[LANGUAGE CODE:  ](https://cloud.google.com/speech-to-text/docs/languages)\n",
    "\n",
    "https://cloud.google.com/speech-to-text/docs/languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said: \n",
      "अभी तो यह चला था अभी तो यह चला था\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   print(\"You said: \\n\" + r.recognize_google(audio, language = 'hi-IN'))\n",
    "except Exception as e:\n",
    "   print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
