knitr::opts_chunk$set(echo = TRUE)
install.packages("shiny")
install.packages("textrank")
install.packages("tidyverse")
install.packages("tidytext")
install.packages("rvest")
install.packages("dplyr")
install.packages("magrittr")
## setup
suppressPackageStartupMessages({
if (!require(textrank)){install.packages("textrank")}
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)  # to scrape a document for summarization
})
## read data via rvest scraping
url <- "http://time.com/5196761/fitbit-ace-kids-fitness-tracker/"
article <- read_html(url) %>%
html_nodes('div[class="padded"]') %>%
html_text()
# read the article
cat(article)
## load data into tibble
article_sentences <- tibble(text = article) %>%
# sentence-tokenizing the article
unnest_tokens(sentence, text, token = "sentences") %>%
# insert setence_id
mutate(sentence_id = row_number()) %>%
# drop frivolous stuff
select(sentence_id, sentence)
head(article_sentences)  # view a few
# word-tokenize too. for IDing keywords
article_words <- article_sentences %>%
unnest_tokens(word, sentence) %>%
# drop stopwords
anti_join(stop_words, by = "word")
head(article_words)
system.time({
article_summary <- textrank_sentences(data = article_sentences,
terminology = article_words)
})  # 0.65 secs
article_summary  # print the actual summary
# first examine the structure of the object of interest
str(article_summary[["sentences"]])
# dplyr::pull() out the top 3 sents by textrank score (== eigenVal score?)
article_summary[["sentences"]] %>%
arrange(desc(textrank)) %>%
slice(1:3) %>%  # dplyr::slice() chooses rows by their ordinal position in the tbl
pull(sentence)
# pull() out the bottom 3 sents by textrank score (== eigenVal score?)
article_summary[["sentences"]] %>%
arrange(textrank) %>%
slice(1:3) %>%
pull(sentence)
article_summary[["sentences"]] %>%
ggplot(aes(textrank_id, textrank, fill = textrank_id)) +
geom_col() +
theme_minimal() +
scale_fill_viridis_c() +
guides(fill = "none") +
labs(x = "Sentence",
y = "TextRank score",
title = "4 Most informative sentences appear within first half of sentences",
subtitle = 'In article "Fitbits Newest Fitness Tracker Is Just for Kids"',
caption = "Source: http://time.com/5196761/fitbit-ace-kids-fitness-tracker/")  # cool!
text <- "India probably lost its spot as the fastest growing major economy to China in the January-March quarter as a chill in domestic and global consumer demand hit manufacturers and service providers.
The slowing economy didn't stop voters giving Prime Minister Narendra Modi a landslide victory in an election concluded earlier this month.
But it puts an onus on him to deliver reforms that can truly unlock growth, which had waxed and waned during his first five years in office. A Reuters survey of economists forecast growth slipped to 6.3% annually in the three months ending in March, its slowest pace in six quarters.
If they are right, India would lag China, which notched 6.4 pct growth in the March quarter, for the first time in one-and-a-half years.
Modi is expected to begin his second term by prioritising growth in an economy that isn't creating enough new jobs for the millions of young Indians entering the labour market each month.
His first task could be finding a new finance minister, as Arun Jaitley has asked to step aside due to health reasons. Whoever takes Jaitley's place will have to draw up a budget due to be presented in July.
The government is widely expected to deliver some fiscal stimulus while keeping the deficit at manageable levels. On the plus side, the Reserve Bank of India could have leeway to reduce interest rates as inflation remains subdued.
The gross domestic product data for January-March quarter and provisional estimates for the whole 2018/19 fiscal year ending in March will be released on Friday around 1200 GMT.
The RBI has lowered its economic growth forecast for 2019/20 fiscal year beginning April to 7.2%.
The central bank's monetary policy committee (MPC), which has cut policy rates by 50 basis points this year, is expected to cut the repo rate by a further 25 basis points at its June 4-6 meeting, bringing it to 5.75%, the lowest since July 2010.
Retail inflation has stayed below 3 percent for last six months, possibly low enough to take the risk of cutting rates without waiting to seeing whether the monsoon rainy season starting next month holds any danger of a spike in food prices.
Several indicators - automobile sales, rail freight, petroleum product consumption, domestic air traffic and imports indicate a slowdown in domestic consumption.
Corporate earnings hit a six-quarter low growth of 10.7% during January-March quarter on weakening consumer sentiment and softening commodity prices, ICRA, the Indian arm of the ratings agency Moody's said on Tuesday, citing a sample of over 300 companies.
The signs of slowdown in domestic demand are visible both in urban and rural areas, Federation of Indian Chambers of Commerce and Industry said in a statement earlier this week, while submitting pre-budget demands to the finance ministry.
Industry chambers have lobbied for a fiscal stimulus including a cut in corporate tax rates and lower interest rates."
article = text
## define func to do all the above in one shot
text_summrzn <- function(article, num_sentences=5){
require(dplyr)
require(magrittr)
require(tidytext)
require(textrank)
## load data into tibble
article_sentences <- tibble(text = article) %>%
unnest_tokens(sentence, text, token = "sentences") %>%    # sentence-tokenizing the article
mutate(sentence_id = row_number()) %>%    # insert setence_id
select(sentence_id, sentence)  # drop frivolous stuff
if (num_sentences > max(article_sentences$sentence_id)) {cat("More sentences in summary than in article."); break}
## word-tokenize too. for IDing keywords
article_words <- article_sentences %>%
unnest_tokens(word, sentence) %>%
# drop stopwords
anti_join(stop_words, by = "word")
## print summary
article_summary <- textrank_sentences(data = article_sentences,
terminology = article_words)
# top k sentences ka list
output1 <- article_summary[["sentences"]] %>%
arrange(desc(textrank)) %>%
slice(1:num_sentences) %>%  # dplyr::slice() chooses rows by their ordinal position in the tbl
pull(sentence)
# top k sentences ka plot
require(ggplot2)
output2 <- article_summary[["sentences"]] %>%
ggplot(aes(textrank_id, textrank, fill = textrank_id)) +
geom_col() +
theme_minimal() +
scale_fill_viridis_c() +
guides(fill = "none") +
labs(x = "Sentence",
y = "TextRank score",
title = "Where do the most informative sentences appear in the article")
return(list(output1, output2))
}  # func ends
system.time({
outp_list = text_summrzn(text, 5)    })  # 0.52 secs
outp_list[[1]]
outp_list[[2]]
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
if (!require(shiny)) {install.packages('shiny')}
library("shiny")
shinyUI(
fluidPage(
titlePanel("k-means Clustering"),  # name the shiny app
sidebarLayout(    # creates a sidebar layout to be filled in
sidebarPanel(   # creates a panel struc in the sidebar layout
# user reads input file into input box here:
fileInput("file1",
"Upload data (csv file with header)"),
# user selects the optimal num of clusters:
numericInput('clusters',
'Number of Clusters',
3,   # default value required
min = 1, max = 9)
),   # end of sidebar panel
## Main Panel area begins.
mainPanel(
tabsetPanel(type = "tabs",   # builds tab struc
tabPanel("Overview",   # leftmost tab
h4(p("Data input")),
p("This app supports only comma separated values (.csv) data file. CSV data file should have headers and the first column of the file should have row names.", align="justify"),
p("Please refer to the link below for sample csv file."),
a(href="https://github.com/sudhir-voleti/sample-data-sets/blob/master/Segmentation%20Discriminant%20and%20targeting%20data/ConneCtorPDASegmentation.csv"
,"Sample data input file"),
br(),
h4('How to use this App'),
p('To use this app, click on',
span(strong("Upload data (csv file with header)")),
'and uppload the csv data file. You can also change the number of clusters to fit in k-means clustering')),
# second tab coming up:
tabPanel("Scree plot",
# plot1 object returned by server.R
plotOutput('plot1')),
# third tab coming up:
tabPanel("Cluster mean",
# obj 'clust_summary' from server.R
tableOutput('clust_summary')),
# fourth tab coming up:
tabPanel("Data",
dataTableOutput('clust_data'))
) # end of tabsetPanel
)# end of main panel
) # end of sidebarLayout
)  # end if fluidPage
) # end of UI
shinyServer(function(input, output) {
Dataset <- reactive({
if (is.null(input$file)) { return(NULL) } else
{
Data <- as.data.frame(
read.csv(input$file1$datapath,
header=TRUE, sep = ","))
rownames(Data) = Data[,1]
Data1 = Data[,2:ncol(Data)]
return(Data1)
}  # else stmt ends
})  # reactive stmt ends
# 'plot1' is output obj for tab 2:
output$plot1 = renderPlot({
data.pca <- prcomp(Dataset(),center = TRUE,scale. = TRUE)
plot(data.pca, type = "l"); abline(h=1)
})
clusters <- reactive({
kmeans(Dataset(), input$clusters)  # user inputs num clusters.
})
# 'clust_summary' is outp obj for tab 3:
output$clust_summary = renderTable({
out = data.frame(
Cluser = row.names(clusters()$centers),
clusters()$centers)
out
})
# 'clust_data' is outp obj for last tab:
output$clust_data = renderDataTable({
out = data.frame(
row_name = row.names(Dataset()),
Dataset(),
Cluster = clusters()$cluster)
out
})
})  # server.R file ends
shinyServer(function(input, output) {
Dataset <- reactive({
if (is.null(input$file)) { return(NULL) } else
{
Data <- as.data.frame(
read.csv(input$file1$datapath,
header=TRUE, sep = ","))
rownames(Data) = Data[,1]
Data1 = Data[,2:ncol(Data)]
return(Data1)
}  # else stmt ends
})  # reactive stmt ends
# 'plot1' is output obj for tab 2:
output$plot1 = renderPlot({
data.pca <- prcomp(Dataset(),center = TRUE,scale. = TRUE)
plot(data.pca, type = "l"); abline(h=1)
})
clusters <- reactive({
kmeans(Dataset(), input$clusters)  # user inputs num clusters.
})
# 'clust_summary' is outp obj for tab 3:
output$clust_summary = renderTable({
out = data.frame(
Cluser = row.names(clusters()$centers),
clusters()$centers)
out
})
# 'clust_data' is outp obj for last tab:
output$clust_data = renderDataTable({
out = data.frame(
row_name = row.names(Dataset()),
Dataset(),
Cluster = clusters()$cluster)
out
})
})  # server.R file ends
#---------------------------------------------------------------------#
#               k-means Clustering App                               #
#---------------------------------------------------------------------#
library("shiny")
# Define ui function
ui <- shinyUI(
fluidPage(
titlePanel("k-means Clustering"),
sidebarLayout(
sidebarPanel(
fileInput("file", "Upload data (csv file with header)"),
numericInput('clusters', 'Number of Clusters', 3,
min = 1, max = 9)     ),   # end of sidebar panel
mainPanel(
tabsetPanel(type = "tabs",
tabPanel("Overview",
h4(p("Data input")),
p("This app supports only comma separated values (.csv) data file. CSV data file should have headers and the first column of the file should have row names.",align="justify"),
p("Please refer to the link below for sample csv file."),
a(href="https://github.com/sudhir-voleti/sample-data-sets/blob/master/Segmentation%20Discriminant%20and%20targeting%20data/ConneCtorPDASegmentation.csv"
,"Sample data input file"),
br(),
h4('How to use this App'),
p('To use this app, click on',
span(strong("Upload data (csv file with header)")),
'and uppload the csv data file. You can also change the number of clusters to fit in k-means clustering')),
tabPanel("Scree plot",
plotOutput('plot1')),
tabPanel("Cluster mean",
tableOutput('clust_summary')),
tabPanel("Data",
dataTableOutput('clust_data'))
) # end of tabsetPanel
)# end of main panel
) # end of sidebarLayout
)  # end if fluidPage
) # end of UI
# Define Server function
server <- shinyServer(function(input, output) {
Dataset <- reactive({
if (is.null(input$file)) { return(NULL) }
else{
Data <- as.data.frame(read.csv(input$file$datapath ,header=TRUE, sep = ","))
rownames(Data) = Data[,1]
Data1 = Data[,2:ncol(Data)]
return(Data1)
}
})
output$plot1 = renderPlot({
data.pca <- prcomp(Dataset(),center = TRUE,scale. = TRUE)
plot(data.pca, type = "l"); abline(h=1)
})
clusters <- reactive({
kmeans(Dataset(), input$clusters)
})
output$clust_summary = renderTable({
out = data.frame(Cluser = row.names(clusters()$centers),clusters()$centers)
out
})
output$clust_data = renderDataTable({
out = data.frame(row_name = row.names(Dataset()),Dataset(),Cluster = clusters()$cluster)
out
})
})
# Now call shinyApp function
shinyApp(ui = ui, server = server)
runApp()
shiny::runApp()
runApp()
runApp()
## setup
suppressPackageStartupMessages({
if (!require(textrank)){install.packages("textrank")}
library(tidyverse)
library(tidytext)
library(textrank)
library(rvest)  # to scrape a document for summarization
})
## read data via rvest scraping
url <- "http://time.com/5196761/fitbit-ace-kids-fitness-tracker/"
article <- read_html(url) %>%
html_nodes('div[class="padded"]') %>%
html_text()
# read the article
cat(article)
## load data into tibble
article_sentences <- tibble(text = article) %>%
# sentence-tokenizing the article
unnest_tokens(sentence, text, token = "sentences") %>%
# insert setence_id
mutate(sentence_id = row_number()) %>%
# drop frivolous stuff
select(sentence_id, sentence)
head(article_sentences)  # view a few
# word-tokenize too. for IDing keywords
article_words <- article_sentences %>%
unnest_tokens(word, sentence) %>%
# drop stopwords
anti_join(stop_words, by = "word")
head(article_words)
system.time({
article_summary <- textrank_sentences(data = article_sentences,
terminology = article_words)
})  # 0.65 secs
article_summary  # print the actual summary
# first examine the structure of the object of interest
str(article_summary[["sentences"]])
# dplyr::pull() out the top 3 sents by textrank score (== eigenVal score?)
article_summary[["sentences"]] %>%
arrange(desc(textrank)) %>%
slice(1:3) %>%  # dplyr::slice() chooses rows by their ordinal position in the tbl
pull(sentence)
# pull() out the bottom 3 sents by textrank score (== eigenVal score?)
article_summary[["sentences"]] %>%
arrange(textrank) %>%
slice(1:3) %>%
pull(sentence)
article_summary[["sentences"]] %>%
ggplot(aes(textrank_id, textrank, fill = textrank_id)) +
geom_col() +
theme_minimal() +
scale_fill_viridis_c() +
guides(fill = "none") +
labs(x = "Sentence",
y = "TextRank score",
title = "4 Most informative sentences appear within first half of sentences",
subtitle = 'In article "Fitbits Newest Fitness Tracker Is Just for Kids"',
caption = "Source: http://time.com/5196761/fitbit-ace-kids-fitness-tracker/")  # cool!
text <- "India probably lost its spot as the fastest growing major economy to China in the January-March quarter as a chill in domestic and global consumer demand hit manufacturers and service providers.
The slowing economy didn't stop voters giving Prime Minister Narendra Modi a landslide victory in an election concluded earlier this month.
But it puts an onus on him to deliver reforms that can truly unlock growth, which had waxed and waned during his first five years in office. A Reuters survey of economists forecast growth slipped to 6.3% annually in the three months ending in March, its slowest pace in six quarters.
If they are right, India would lag China, which notched 6.4 pct growth in the March quarter, for the first time in one-and-a-half years.
Modi is expected to begin his second term by prioritising growth in an economy that isn't creating enough new jobs for the millions of young Indians entering the labour market each month.
His first task could be finding a new finance minister, as Arun Jaitley has asked to step aside due to health reasons. Whoever takes Jaitley's place will have to draw up a budget due to be presented in July.
The government is widely expected to deliver some fiscal stimulus while keeping the deficit at manageable levels. On the plus side, the Reserve Bank of India could have leeway to reduce interest rates as inflation remains subdued.
The gross domestic product data for January-March quarter and provisional estimates for the whole 2018/19 fiscal year ending in March will be released on Friday around 1200 GMT.
The RBI has lowered its economic growth forecast for 2019/20 fiscal year beginning April to 7.2%.
The central bank's monetary policy committee (MPC), which has cut policy rates by 50 basis points this year, is expected to cut the repo rate by a further 25 basis points at its June 4-6 meeting, bringing it to 5.75%, the lowest since July 2010.
Retail inflation has stayed below 3 percent for last six months, possibly low enough to take the risk of cutting rates without waiting to seeing whether the monsoon rainy season starting next month holds any danger of a spike in food prices.
Several indicators - automobile sales, rail freight, petroleum product consumption, domestic air traffic and imports indicate a slowdown in domestic consumption.
Corporate earnings hit a six-quarter low growth of 10.7% during January-March quarter on weakening consumer sentiment and softening commodity prices, ICRA, the Indian arm of the ratings agency Moody's said on Tuesday, citing a sample of over 300 companies.
The signs of slowdown in domestic demand are visible both in urban and rural areas, Federation of Indian Chambers of Commerce and Industry said in a statement earlier this week, while submitting pre-budget demands to the finance ministry.
Industry chambers have lobbied for a fiscal stimulus including a cut in corporate tax rates and lower interest rates."
article = text
## define func to do all the above in one shot
text_summrzn <- function(article, num_sentences=5){
require(dplyr)
require(magrittr)
require(tidytext)
require(textrank)
## load data into tibble
article_sentences <- tibble(text = article) %>%
unnest_tokens(sentence, text, token = "sentences") %>%    # sentence-tokenizing the article
mutate(sentence_id = row_number()) %>%    # insert setence_id
select(sentence_id, sentence)  # drop frivolous stuff
if (num_sentences > max(article_sentences$sentence_id)) {cat("More sentences in summary than in article."); break}
## word-tokenize too. for IDing keywords
article_words <- article_sentences %>%
unnest_tokens(word, sentence) %>%
# drop stopwords
anti_join(stop_words, by = "word")
## print summary
article_summary <- textrank_sentences(data = article_sentences,
terminology = article_words)
# top k sentences ka list
output1 <- article_summary[["sentences"]] %>%
arrange(desc(textrank)) %>%
slice(1:num_sentences) %>%  # dplyr::slice() chooses rows by their ordinal position in the tbl
pull(sentence)
# top k sentences ka plot
require(ggplot2)
output2 <- article_summary[["sentences"]] %>%
ggplot(aes(textrank_id, textrank, fill = textrank_id)) +
geom_col() +
theme_minimal() +
scale_fill_viridis_c() +
guides(fill = "none") +
labs(x = "Sentence",
y = "TextRank score",
title = "Where do the most informative sentences appear in the article")
return(list(output1, output2))
}  # func ends
system.time({
outp_list = text_summrzn(text, 5)    })  # 0.52 secs
outp_list[[1]]
outp_list[[2]]
shiny::runApp('~/Dropbox/isb/Term1/Text Analytics/Anmol')
ui <- fluidPage(
theme = shinytheme("united"),
titlePanel(title = div(
img(
src = "isb.png",
height = "5%",
width = "5%",
align = "right"
),
"Q3 : NLP Workflow"
)),
sidebarLayout(
sidebarPanel(
# File upload
fileInput("file", "Upload text file (english only)",
accept = c("text/comma-separated-values,text/plain")),
# Add horizontal line
tags$hr()
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Data file ----
tableOutput("contents")
)
)
)
runApp('~/Dropbox/isb/Term1/Text Analytics/Anmol')
runApp('~/Dropbox/isb/Term1/Text Analytics/Anmol')
runApp('~/Dropbox/isb/Term1/Text Analytics/Anmol')
runApp('~/Dropbox/isb/Term1/Text Analytics/Anmol')
runApp('~/Dropbox/isb/Term1/Text Analytics/Anmol')
