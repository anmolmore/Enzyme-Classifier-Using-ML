
udera@quickstart original]$ spark-submit MovieRecommendations.py 51
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/parquet/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/avro/avro-tools-1.7.6-cdh5.13.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/05/26 11:16:18 INFO spark.SparkContext: Running Spark version 1.6.0
19/05/26 11:16:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/05/26 11:16:19 WARN util.Utils: Your hostname, quickstart.cloudera resolves to a loopback address: 127.0.0.1; using 10.0.2.15 instead (on interface eth0)
19/05/26 11:16:19 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address
19/05/26 11:16:19 INFO spark.SecurityManager: Changing view acls to: cloudera
19/05/26 11:16:19 INFO spark.SecurityManager: Changing modify acls to: cloudera
19/05/26 11:16:19 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
19/05/26 11:16:19 INFO util.Utils: Successfully started service 'sparkDriver' on port 37391.
19/05/26 11:16:20 INFO slf4j.Slf4jLogger: Slf4jLogger started
19/05/26 11:16:20 INFO Remoting: Starting remoting
19/05/26 11:16:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.2.15:51408]
19/05/26 11:16:20 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@10.0.2.15:51408]
19/05/26 11:16:20 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 51408.
19/05/26 11:16:20 INFO spark.SparkEnv: Registering MapOutputTracker
19/05/26 11:16:20 INFO spark.SparkEnv: Registering BlockManagerMaster
19/05/26 11:16:20 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-72420929-20b1-443d-ae0d-259c8eec8c71
19/05/26 11:16:20 INFO storage.MemoryStore: MemoryStore started with capacity 534.5 MB
19/05/26 11:16:20 INFO spark.SparkEnv: Registering OutputCommitCoordinator
19/05/26 11:16:20 INFO server.Server: jetty-8.y.z-SNAPSHOT
19/05/26 11:16:20 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
19/05/26 11:16:20 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
19/05/26 11:16:20 INFO ui.SparkUI: Started SparkUI at http://10.0.2.15:4040
19/05/26 11:16:28 INFO util.Utils: Copying /home/cloudera/Downloads/original/MovieRecommendations.py to /tmp/spark-4a019d81-3366-4872-9afb-0b9bcc2a128d/userFiles-8b9cf003-7755-4dec-b6f7-ff5f12306a57/MovieRecommendations.py
19/05/26 11:16:28 INFO spark.SparkContext: Added file file:/home/cloudera/Downloads/original/MovieRecommendations.py at file:/home/cloudera/Downloads/original/MovieRecommendations.py with timestamp 1558894588296
19/05/26 11:16:28 INFO executor.Executor: Starting executor ID driver on host localhost
19/05/26 11:16:28 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33522.
19/05/26 11:16:28 INFO netty.NettyBlockTransferService: Server created on 33522
19/05/26 11:16:28 INFO storage.BlockManagerMaster: Trying to register BlockManager
19/05/26 11:16:28 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:33522 with 534.5 MB RAM, BlockManagerId(driver, localhost, 33522)
19/05/26 11:16:28 INFO storage.BlockManagerMaster: Registered BlockManager

Loading movie names...
19/05/26 11:16:29 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 207.2 KB, free 534.3 MB)
19/05/26 11:16:29 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.6 KB, free 534.3 MB)
19/05/26 11:16:29 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33522 (size: 24.6 KB, free: 534.5 MB)
19/05/26 11:16:29 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
19/05/26 11:16:30 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
Traceback (most recent call last):
  File "/home/cloudera/Downloads/original/MovieRecommendations.py", line 52, in <module>
    joinedRatings = ratings.join(ratings)
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1611, in join
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/join.py", line 53, in python_join
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/join.py", line 41, in _do_python_join
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 529, in union
  File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 2363, in getNumPartitions
  File "/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py", line 813, in __call__
  File "/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/protocol.py", line 308, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o20.partitions.
: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://quickstart.cloudera:8020/user/cloudera/u.data
	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:202)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:64)
	at org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:46)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)
	at py4j.Gateway.invoke(Gateway.java:259)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:209)
	at java.lang.Thread.run(Thread.java:745)

19/05/26 11:16:30 INFO spark.SparkContext: Invoking stop() from shutdown hook
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
19/05/26 11:16:30 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
19/05/26 11:16:30 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.2.15:4040
19/05/26 11:16:30 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/05/26 11:16:30 INFO storage.MemoryStore: MemoryStore cleared
19/05/26 11:16:30 INFO storage.BlockManager: BlockManager stopped
19/05/26 11:16:30 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
19/05/26 11:16:30 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/05/26 11:16:30 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
19/05/26 11:16:30 INFO spark.SparkContext: Successfully stopped SparkContext
19/05/26 11:16:30 INFO util.ShutdownHookManager: Shutdown hook called
19/05/26 11:16:30 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-4a019d81-3366-4872-9afb-0b9bcc2a128d/pyspark-f7bc837a-3bd4-4098-8c09-a588903651c3
19/05/26 11:16:30 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-4a019d81-3366-4872-9afb-0b9bcc2a128d
19/05/26 11:16:30 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
19/05/26 11:16:30 INFO Remoting: Remoting shut down
19/05/26 11:16:30 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
