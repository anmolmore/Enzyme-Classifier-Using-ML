{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members :\n",
    "- Anmol More : 11915043\n",
    "- Dharani Kiran Kavuri : 11915033\n",
    "- Shubhendu Vimal : 11915067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :\n",
    "- https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "- https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
    "- https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "- https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "\n",
    "#import libraries for feature processing\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import necessary ml algorithms\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Data Collection </H2>\n",
    "\n",
    "Collect data from wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref : https://pypi.org/project/wikipedia/\n",
    "topics = ['Brexit', 'Donald Trump', 'Game of Thrones', 'Bitcoin']\n",
    "for topic in topics :\n",
    "    wiki_page = wikipedia.WikipediaPage(title = topic)\n",
    "    with open(topic + \".txt\", \"w\") as text_file:\n",
    "        text_file.write(wiki_page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a labeled dataframe by readling sentences from text corpus and combine all dataframes. Steps -\n",
    "- read back text files stored after scrapping wikipedia\n",
    "- Use nltk to get sentences\n",
    "- prepare dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text   topic\n",
      "213  The deal was voted against 391 to 242, a loss ...  Brexit\n",
      "98   According to the BBC, \"The prime minister ackn...  Brexit\n",
      "368  === Scotland ===\\n\\nAs suggested by the Scotti...  Brexit\n",
      "                                                  text         topic\n",
      "411  The official counts were 304 and 227 respectiv...  Donald Trump\n",
      "204  In response to mounting complaints, Trump's te...  Donald Trump\n",
      "221  His first published book in 1987 was Trump: Th...  Donald Trump\n",
      "                                                  text            topic\n",
      "27   He introduced gray tones into a black-and-whit...  Game of Thrones\n",
      "84   The only exceptions were Peter Dinklage and Se...  Game of Thrones\n",
      "157  At the beginning of the fourth season Engelen'...  Game of Thrones\n",
      "                                                  text    topic\n",
      "288  In July 2017, billionaire Howard Marks referre...  Bitcoin\n",
      "20   During its 30 months of existence, beginning i...  Bitcoin\n",
      "104  The PoW requires miners to find a number calle...  Bitcoin\n"
     ]
    }
   ],
   "source": [
    "def prepare_df(topic) :\n",
    "    file_reader = open(topic + \".txt\",\"r\",encoding=\"utf-8\")\n",
    "    text = file_reader.read()\n",
    "    file_reader.close()\n",
    "\n",
    "    df = pd.DataFrame(columns=['text', 'topic'])\n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences :\n",
    "        df = df.append({'text': sentence, 'topic': topic}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "brexit_df = prepare_df(\"Brexit\")\n",
    "trump_df = prepare_df(\"Donald Trump\")\n",
    "got_df = prepare_df(\"Game of Thrones\")\n",
    "bitcoin_df = prepare_df(\"Bitcoin\")\n",
    "\n",
    "print(brexit_df.sample(3))\n",
    "print(trump_df.sample(3))\n",
    "print(got_df.sample(3))\n",
    "print(bitcoin_df.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check sampled data from combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>S. J. Clarkson has been announced to direct an...</td>\n",
       "      <td>Game of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>=== Racial views ===\\n\\nTrump has a history of...</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Several states immediately challenged the DACA...</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>In April 2017 an online petition aimed at ment...</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Mueller also investigated the Trump campaign's...</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text            topic\n",
       "347  S. J. Clarkson has been announced to direct an...  Game of Thrones\n",
       "258  === Racial views ===\\n\\nTrump has a history of...     Donald Trump\n",
       "496  Several states immediately challenged the DACA...     Donald Trump\n",
       "87   In April 2017 an online petition aimed at ment...     Donald Trump\n",
       "608  Mueller also investigated the Trump campaign's...     Donald Trump"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([brexit_df, trump_df, got_df, bitcoin_df])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Data Cleaning and Preparation </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_line) :\n",
    "    tokens = word_tokenize(text_line)\n",
    "    tokens = [w.lower() for w in tokens]  #lowercase the word tokens\n",
    "\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [token.translate(table) for token in tokens]\n",
    "    words = [word for word in tokens if word.isalpha()]  #remove all alpha numeric\n",
    "\n",
    "    stop_words = stopwords.words('english')  #remove all stop words\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "    return ' '.join([str(word) for word in words])\n",
    "\n",
    "df['clean_text'] = df['text'].apply(lambda line: clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>The main reason people voted Remain was that \"...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>main reason peopl vote remain risk vote leav e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Itzkoff also wrote that critics fear that \"rap...</td>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>itzkoff also wrote critic fear rape becom perv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>In October 2016, European Commission President...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>octob european commiss presid juncker said eu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>=== Popular culture ===\\n\\nTrump has been the ...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>popular cultur trump subject comedian flash ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MPs also voted on four options on 1 April 2019...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>mp also vote four option april second round in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>He has repeatedly criticized the Joint Compreh...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>repeatedli critic joint comprehens plan action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Trump also acquired a partially completed buil...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>trump also acquir partial complet build atlant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Additionally, the plan appears to breach stand...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>addit plan appear breach standard wto rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>There may be an interim deal between the time ...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>may interim deal time uk leav eu final relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>There were an estimated 24 million bitcoin use...</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>estim million bitcoin user primarili use bitco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text            topic  \\\n",
       "120  The main reason people voted Remain was that \"...           Brexit   \n",
       "286  Itzkoff also wrote that critics fear that \"rap...  Game of Thrones   \n",
       "150  In October 2016, European Commission President...           Brexit   \n",
       "296  === Popular culture ===\\n\\nTrump has been the ...     Donald Trump   \n",
       "50   MPs also voted on four options on 1 April 2019...           Brexit   \n",
       "527  He has repeatedly criticized the Joint Compreh...     Donald Trump   \n",
       "143  Trump also acquired a partially completed buil...     Donald Trump   \n",
       "194  Additionally, the plan appears to breach stand...           Brexit   \n",
       "387  There may be an interim deal between the time ...           Brexit   \n",
       "300  There were an estimated 24 million bitcoin use...          Bitcoin   \n",
       "\n",
       "                                            clean_text  \n",
       "120  main reason peopl vote remain risk vote leav e...  \n",
       "286  itzkoff also wrote critic fear rape becom perv...  \n",
       "150  octob european commiss presid juncker said eu ...  \n",
       "296  popular cultur trump subject comedian flash ca...  \n",
       "50   mp also vote four option april second round in...  \n",
       "527  repeatedli critic joint comprehens plan action...  \n",
       "143  trump also acquir partial complet build atlant...  \n",
       "194         addit plan appear breach standard wto rule  \n",
       "387  may interim deal time uk leav eu final relatio...  \n",
       "300  estim million bitcoin user primarili use bitco...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Split data in train and test set in 70:30 ratio </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bitcoin', 'Brexit', 'Donald Trump', 'Game of Thrones']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['topic'], test_size=.3)\n",
    "\n",
    "#specify own encoding scheme so, it becomes easier to identify later\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(topics)\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "encoded_topics = list(encoder.inverse_transform([0,1,2,3]))\n",
    "print(encoded_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very train and test sets are correcly divided. It would do random shuffle by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size : (1192,)\n",
      "Test dataset size : (512,)\n",
      "Labeled dataset size : (1192,)\n",
      "Labeled dataset size : (512,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset size :\",X_train.shape)\n",
    "print(\"Test dataset size :\",X_test.shape)\n",
    "\n",
    "print(\"Labeled dataset size :\",y_train.shape)\n",
    "print(\"Labeled dataset size :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Run ML Algoithms </H2>\n",
    "\n",
    "Steps - \n",
    "- Create count vector and vectorized tfidf\n",
    "- Create word vector for each of matrix\n",
    "- Fit ML algorithms on both\n",
    "- Check confusion matrix for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check train and test set size :\n",
      "(1192, 4315) (512, 4315)\n"
     ]
    }
   ],
   "source": [
    "#Ref : https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "count_vect = CountVectorizer()\n",
    "X_train_count_vect = count_vect.fit_transform(X_train)\n",
    "X_test_count_vect = count_vect.transform(X_test)\n",
    "print(\"Check train and test set size :\")\n",
    "print(X_train_count_vect.shape, X_test_count_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check train and test set size :\n",
      "(1192, 4315) (512, 4315)\n"
     ]
    }
   ],
   "source": [
    "#Try multiple combinations, go with default for now\n",
    "# use_idf = False, \n",
    "# smooth_idf = True,\n",
    "# sublinear_tf = False,\n",
    "# ngram_range=(1,1)\n",
    "tfidf_vector = TfidfVectorizer()\n",
    "X_train_tfidf_vect = tfidf_vector.fit_transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vector.transform(X_test)\n",
    "print(\"Check train and test set size :\")\n",
    "print(X_train_tfidf_vect.shape, X_test_tfidf_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Navie Bayes </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       0.95      0.94      0.95        87\n",
      "         Brexit       0.92      0.98      0.95       125\n",
      "   Donald Trump       0.95      0.93      0.94       177\n",
      "Game of Thrones       0.94      0.93      0.93       123\n",
      "\n",
      "      micro avg       0.94      0.94      0.94       512\n",
      "      macro avg       0.94      0.94      0.94       512\n",
      "   weighted avg       0.94      0.94      0.94       512\n",
      "\n",
      "accurancy score on count vector : 0.94140625\n",
      "\n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       0.99      0.83      0.90        87\n",
      "         Brexit       0.95      0.93      0.94       125\n",
      "   Donald Trump       0.80      0.98      0.88       177\n",
      "Game of Thrones       0.97      0.80      0.87       123\n",
      "\n",
      "      micro avg       0.90      0.90      0.90       512\n",
      "      macro avg       0.93      0.88      0.90       512\n",
      "   weighted avg       0.91      0.90      0.90       512\n",
      "\n",
      "accurancy score on tfidf vector : 0.896484375\n"
     ]
    }
   ],
   "source": [
    "MBModel = MultinomialNB().fit(X_train_count_vect, y_train)\n",
    "predicted = MBModel.predict(X_test_count_vect)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on count vector :\", accuracy_score(y_test, predicted))\n",
    "\n",
    "MBModel = MultinomialNB().fit(X_train_tfidf_vect, y_train)\n",
    "predicted = MBModel.predict(X_test_tfidf_vect)\n",
    "print(\"\\n\\n\")\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on tfidf vector :\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Random Forest </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       0.67      0.98      0.79        87\n",
      "         Brexit       0.88      0.94      0.91       125\n",
      "   Donald Trump       0.93      0.77      0.85       177\n",
      "Game of Thrones       0.94      0.80      0.86       123\n",
      "\n",
      "      micro avg       0.86      0.86      0.86       512\n",
      "      macro avg       0.86      0.87      0.85       512\n",
      "   weighted avg       0.88      0.86      0.86       512\n",
      "\n",
      "accurancy score on count vector : 0.85546875\n",
      "\n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       0.93      0.91      0.92        87\n",
      "         Brexit       0.89      0.95      0.92       125\n",
      "   Donald Trump       0.84      0.92      0.88       177\n",
      "Game of Thrones       0.96      0.78      0.86       123\n",
      "\n",
      "      micro avg       0.89      0.89      0.89       512\n",
      "      macro avg       0.90      0.89      0.89       512\n",
      "   weighted avg       0.90      0.89      0.89       512\n",
      "\n",
      "accurancy score on tfidf : 0.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmol/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/anmol/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier().fit(X_train_count_vect, y_train)\n",
    "predicted = rf_model.predict(X_test_count_vect)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on count vector :\", accuracy_score(y_test,predicted))\n",
    "\n",
    "rf_model = RandomForestClassifier().fit(X_train_tfidf_vect, y_train)\n",
    "predicted = rf_model.predict(X_test_tfidf_vect)\n",
    "print(\"\\n\\n\")\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on tfidf :\", accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> SGD Classifier </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       0.93      0.91      0.92        87\n",
      "         Brexit       0.92      0.92      0.92       125\n",
      "   Donald Trump       0.91      0.90      0.91       177\n",
      "Game of Thrones       0.90      0.93      0.91       123\n",
      "\n",
      "      micro avg       0.91      0.91      0.91       512\n",
      "      macro avg       0.92      0.91      0.91       512\n",
      "   weighted avg       0.91      0.91      0.91       512\n",
      "\n",
      "accurancy score on count vector : 0.9140625\n",
      "\n",
      "\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       0.96      0.93      0.95        87\n",
      "         Brexit       0.97      0.93      0.95       125\n",
      "   Donald Trump       0.90      0.96      0.93       177\n",
      "Game of Thrones       0.94      0.92      0.93       123\n",
      "\n",
      "      micro avg       0.94      0.94      0.94       512\n",
      "      macro avg       0.94      0.93      0.94       512\n",
      "   weighted avg       0.94      0.94      0.94       512\n",
      "\n",
      "accurancy score on tfidf : 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmol/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd_model = SGDClassifier().fit(X_train_count_vect, y_train)\n",
    "predicted = sgd_model.predict(X_test_count_vect)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on count vector :\", accuracy_score(y_test,predicted))\n",
    "\n",
    "sgd_model = SGDClassifier().fit(X_train_tfidf_vect, y_train)\n",
    "predicted = sgd_model.predict(X_test_tfidf_vect)\n",
    "print(\"\\n\\n\")\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on tfidf :\", accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Gradient Boosted Trees </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       1.00      0.83      0.91        87\n",
      "         Brexit       0.98      0.90      0.94       125\n",
      "   Donald Trump       0.74      0.98      0.85       177\n",
      "Game of Thrones       0.98      0.73      0.84       123\n",
      "\n",
      "      micro avg       0.88      0.88      0.88       512\n",
      "      macro avg       0.93      0.86      0.88       512\n",
      "   weighted avg       0.90      0.88      0.88       512\n",
      "\n",
      "accurancy score on count vector : 0.875\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Bitcoin       1.00      0.84      0.91        87\n",
      "         Brexit       0.97      0.90      0.93       125\n",
      "   Donald Trump       0.75      0.97      0.85       177\n",
      "Game of Thrones       0.95      0.73      0.83       123\n",
      "\n",
      "      micro avg       0.87      0.87      0.87       512\n",
      "      macro avg       0.92      0.86      0.88       512\n",
      "   weighted avg       0.89      0.87      0.87       512\n",
      "\n",
      "accurancy score on tfidf vector : 0.873046875\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier().fit(X_train_count_vect, y_train)\n",
    "predicted = xgb_model.predict(X_test_count_vect)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on count vector :\", accuracy_score(y_test,predicted))\n",
    "\n",
    "xgb_model = XGBClassifier().fit(X_train_tfidf_vect, y_train)\n",
    "predicted = xgb_model.predict(X_test_tfidf_vect)\n",
    "print(metrics.classification_report(y_test, predicted, target_names=encoded_topics))\n",
    "print(\"accurancy score on tfidf vector :\", accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Conclusion </H3>\n",
    "\n",
    "**Ensemble method seems to performing best for our corpus**\n",
    "\n",
    "*In general Tfidf vector format performs better than count vector. However we don't have a clear winner. Also ML algorithsm performs much better than LTM models built in R*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
